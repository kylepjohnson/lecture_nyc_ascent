{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/auto_examples/applications/topics_extraction_with_nmf_lda.html\n",
    "\n",
    "from __future__ import print_function\n",
    "from time import time\n",
    "\n",
    "import pandas\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation  # v. 0.17.1\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def csv_to_df(csv_file):\n",
    "    \"\"\"Open csv, return Pandas DataFrame.\"\"\"\n",
    "    dataframe = pandas.read_csv(csv_file, \n",
    "                             delimiter='|', \n",
    "                             error_bad_lines=False, \n",
    "                             warn_bad_lines=False,\n",
    "                            )\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_samples = 2000\n",
    "n_features = 1000\n",
    "n_topics = 10\n",
    "n_top_words = 20\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataframe_popular = csv_to_df('../tweets/tweets_popular.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_samples = dataframe_popular['_text'].tolist()  # list of str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf-idf features for NMF...\n",
      "done in 0.158s.\n"
     ]
    }
   ],
   "source": [
    "# Use tf-idf features for NMF.\n",
    "print(\"Extracting tf-idf features for NMF...\")\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, #max_features=n_features,\n",
    "                                   stop_words='english')\n",
    "t0 = time()\n",
    "tfidf = tfidf_vectorizer.fit_transform(data_samples)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@CringeLMAO: Easy there m8 https://t.co/dnF3Wqdt1C',\n",
       " '@AustinMahone: Just posted a photo https://t.co/hXFg6TyuzE',\n",
       " \"@Ashton5SOS: Some days I drink way to much coffee and fill your Twitter feeds with stupid replies and pointless videos, I ain't sorry ok\"]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_samples[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf features for LDA...\n",
      "done in 0.212s.\n"
     ]
    }
   ],
   "source": [
    "# Use tf (raw term count) features for LDA.\n",
    "print(\"Extracting tf features for LDA...\")\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2,\n",
    "                                max_features=n_features,\n",
    "                                stop_words='english')\n",
    "t0 = time()\n",
    "tf = tf_vectorizer.fit_transform(data_samples)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the NMF model with tf-idf features,n_samples=2000 and n_features=1000...\n",
      "done in 0.242s.\n",
      "\n",
      "Topics in NMF model:\n",
      "Topic #0:\n",
      "https day new time rt want sexualgif justin grammy happy oh bieber people girl goals amp fuck black grammys performance\n",
      "Topic #1:\n",
      "love justinbieber beliebers ready did grammys performance tonight 3zhzx54wr0 thank remember riuhvhdg8z stage mylovaticsaremylife believed mtvema ddlovato billboard diplo skrillex\n",
      "Topic #2:\n",
      "im ice cube snapchat dead worldstarfunny cae4iqzfwg https crying lom9ctefao besideyoustyles deadhdj playfuily etricnhsxz j0hbgendly woridstarhiph0p oy2wfefsyp xl8g2p64sz freddyamazin woridstarcomedy\n",
      "Topic #3:\n",
      "life djkingassassin warriors wyclef level struggle matter maddi_says headsaudio bumpin groovin trying girl new rest forward want looking camerondallas tweetlikeagiri\n",
      "Topic #4:\n",
      "gets watch funnier woridstarhiph0p hndwodypak https t3ttxk1icp worldstarfunny lzibp2skdl niggacommentary qua1oapdyy woridstarcomedy gdevfhnzbl atp6wvvgul fillwerrell dory time kc5ieskdr8 4kthm0lrkq woridstarhiphop\n",
      "Topic #5:\n",
      "kanyewest debt puts americans education started chance fuck greatness shut enjoy struggle level matter dream god likable worried aight people\n",
      "Topic #6:\n",
      "thegrammys grammys taylorswift13 congrats best album screaming pop vocal 1989 6gqbpr2jmw ladygaga skrillex diplo justinbieber performance intelinmusic kendricklamar amp winning\n",
      "Topic #7:\n",
      "need carterreynolds good pic mom date boys fish pics instagram work keeping god oh caught dog sodamntrue nap graysondolan caug\n",
      "Topic #8:\n",
      "like just don looks love internallyiost realized look people talk welcome start olive garden girl drink hi know http understand\n",
      "Topic #9:\n",
      "kendrick lamar beyonc reactionbeyonce toqfog9yqt artistic inspiration creative jackjackjohnson mind performance grammys 2016 tribecalledgod h0vzipci7v blacklivesmatter gwq6viygmd onlyhiphopfacts https grammy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit the NMF model\n",
    "print(\"Fitting the NMF model with tf-idf features,\"\n",
    "      \"n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "t0 = time()\n",
    "nmf = NMF(n_components=n_topics, \n",
    "          random_state=1,\n",
    "          alpha=.1, \n",
    "          l1_ratio=.5).fit(tfidf)\n",
    "exit()\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "print(\"\\nTopics in NMF model:\")\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_samples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-98b48b48bee3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m print(\"Fitting LDA models with tf features, n_samples=%d and n_features=%d...\"\n\u001b[0;32m----> 2\u001b[0;31m       % (n_samples, n_features))\n\u001b[0m\u001b[1;32m      3\u001b[0m lda = LatentDirichletAllocation(n_topics=n_topics, max_iter=5,\n\u001b[1;32m      4\u001b[0m                                 \u001b[0mlearning_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'online'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_offset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                 random_state=0)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n_samples' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "print(\"Fitting LDA models with tf features, n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "lda = LatentDirichletAllocation(n_topics=n_topics, max_iter=5,\n",
    "                                learning_method='online', learning_offset=50.,\n",
    "                                random_state=0)\n",
    "t0 = time()\n",
    "lda.fit(tf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "print(\"\\nTopics in LDA model:\")\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
