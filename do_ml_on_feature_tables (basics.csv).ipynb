{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script to demo scikit for tweet popular/unpopular classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import csv\n",
    "import datetime as dt\n",
    "import os\n",
    "import platform\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def csv_to_dict_cesar(csv_filename):\n",
    "    # Let's say, We are intersted in only count features\n",
    "    count_features = ['_char_count', '_hashtag_count', '_word_count', '_url_count']\n",
    "    with open(csv_filename) as f:\n",
    "        features = [({k: int(v) for k, v in row.items() if k in count_features}, row['_popular'])\n",
    "                    for row in csv.DictReader(f, skipinitialspace=True)]\n",
    "        X = [f[0] for f in features]\n",
    "        Y = [f[1] for f in features]\n",
    "    return (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def csv_to_dict(csv_filename):\n",
    "    \"\"\"Open feature table with csv library.\n",
    "    \n",
    "    Task: Run with '_rt_count'. See the good results!\n",
    "    \"\"\"\n",
    "    non_numeric_features = ['', '_text', '_urls', '_mentions', '_hashtags', \n",
    "                            '_tweet_datetime', '_popular', '_rt_count']\n",
    "    with open(csv_filename, 'rU') as f:\n",
    "        rows = csv.DictReader(f, skipinitialspace=True, delimiter='|')\n",
    "        labels = [row['_popular'] for row in rows]\n",
    "\n",
    "    features = []\n",
    "    with open(csv_filename, 'rU') as f:\n",
    "        rows = csv.DictReader(f, skipinitialspace=True, delimiter='|')\n",
    "        for row in rows:\n",
    "            #print(row)\n",
    "            row_dict = {}\n",
    "            for k, v in row.items():\n",
    "                if k not in non_numeric_features:\n",
    "                    try:\n",
    "                        row_dict[k] = int(v)\n",
    "                    # these tries catch a few junk entries\n",
    "                    except TypeError:\n",
    "                        row_dict[k] = 0\n",
    "                    except ValueError:\n",
    "                        row_dict[k] = 0\n",
    "\n",
    "            #row_dict = {k: int(v) for k, v in row.items() if k not in non_numeric_features}\n",
    "            features.append(row_dict)                \n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def csv_to_df(csv_file):\n",
    "    \"\"\"Open csv with Pandas DataFrame, then convert to dict \n",
    "    and return.\n",
    "    \n",
    "    TODO: Fix this.\n",
    "    \"\"\"\n",
    "    \n",
    "    dataframe = pandas.read_csv(csv_file, \n",
    "                                encoding='utf-8', \n",
    "                                engine='python', \n",
    "                                sep='|',\n",
    "                                delimiter='|',\n",
    "                                index_col=0)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(csv_filename):\n",
    "    \n",
    "    # Open .csv and load into df\n",
    "    #features = csv_to_dict_cesar(csv_filename)\n",
    "    #vec = DictVectorizer()\n",
    "    #data = features[0]  # list of dict: [{'_word_count': 5, '_hashtag_count': 0, '_char_count': 50, '_url_count': 0}\n",
    "    #target = features[1]  # list of str: ['TRUE', 'TRUE', 'FALSE', ...]\n",
    "    \n",
    "    print('Loading CSV into dict ...')\n",
    "    t0 = dt.datetime.utcnow()\n",
    "    data, target = csv_to_dict(csv_filename)\n",
    "    print('... finished in {} secs.'.format(dt.datetime.utcnow() - t0))\n",
    "    print()\n",
    "    \n",
    "    print('Loading dict into vectorizer')\n",
    "    t0 = dt.datetime.utcnow()\n",
    "    vec = DictVectorizer()\n",
    "    X = vec.fit_transform(data).toarray()  # change to numpy array\n",
    "    Y = np.array(target)  # change to numpy array\n",
    "    print('... finished in {} secs.'.format(dt.datetime.utcnow() - t0))\n",
    "    print()\n",
    "\n",
    "    \n",
    "    '''\n",
    "    -In case we need to know the features\n",
    "    '''\n",
    "    feature_names = vec.get_feature_names()\n",
    "\n",
    "    '''\n",
    "    -Dividing the data into train and test\n",
    "    -random_state is pseudo-random number generator state used for\n",
    "     random sampling\n",
    "    '''\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=0)\n",
    "    \n",
    "    # write models dir if not present\n",
    "    models_dir = 'models'\n",
    "    if not os.path.isdir(models_dir):\n",
    "        os.mkdir(models_dir)\n",
    "\n",
    "    '''\n",
    "    -PREPOCESSING \n",
    "    -Here, scaled data has zero mean and unit varience\n",
    "    -We save the scaler to later use with testing/prediction data\n",
    "    '''\n",
    "    print('Scaling data ...')\n",
    "    t0 = dt.datetime.utcnow()\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    joblib.dump(scaler, 'models/scaler.pickle')\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    print('... finished in {} secs.'.format(dt.datetime.utcnow() - t0))\n",
    "    print()\n",
    "    \n",
    "\n",
    "    '''\n",
    "    -This is where we define the models\n",
    "    -Here, I use SVM and Decision tree with pre-defined parameters\n",
    "    -We can learn these parameters given our data\n",
    "    '''\n",
    "    print('Defining and fitting models ...')\n",
    "    t0 = dt.datetime.utcnow()   \n",
    "    clf0 = svm.LinearSVC(C=100.)\n",
    "    clf1 = tree.DecisionTreeClassifier()\n",
    "\n",
    "    clf0.fit(X_train_scaled, Y_train)\n",
    "    clf1.fit(X_train_scaled, Y_train)\n",
    "\n",
    "    joblib.dump(clf0, 'models/svc.pickle')\n",
    "    joblib.dump(clf1, 'models/tree.pickle')\n",
    "\n",
    "    print('... finished in {} secs.'.format(dt.datetime.utcnow() - t0))\n",
    "    print()\n",
    "    \n",
    "\n",
    "    Y_prediction_svc = clf0.predict(X_test_scaled)\n",
    "    print('svc_predictions ', Y_prediction_svc)\n",
    "    Y_prediction_tree = clf1.predict(X_test_scaled)\n",
    "    print('tree_predictions ', Y_prediction_tree)\n",
    "    expected = Y_test\n",
    "    print('actual_values   ', expected)\n",
    "\n",
    "    '''\n",
    "    Classifiation metrics\n",
    "    (Case 1): SVMs\n",
    "    '''\n",
    "    print()\n",
    "    print('----Linear SVC_report--------------------------')\n",
    "    print(classification_report(expected, Y_prediction_svc))\n",
    "\n",
    "    '''\n",
    "    Classification metrics\n",
    "    (case 2): Decision tree\n",
    "    '''\n",
    "    print()\n",
    "    print('----Tree_report--------------------------------')\n",
    "    print(classification_report(expected, Y_prediction_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CSV into dict ...\n",
      "... finished in 0:00:00.549396 secs.\n",
      "\n",
      "Loading dict into vectorizer\n",
      "... finished in 0:00:00.195202 secs.\n",
      "\n",
      "Scaling data ...\n",
      "... finished in 0:00:00.004574 secs.\n",
      "\n",
      "Defining and fitting models ...\n",
      "... finished in 0:00:03.730801 secs.\n",
      "\n",
      "svc_predictions  ['False' 'False' 'False' ..., 'False' 'False' 'False']\n",
      "tree_predictions  ['False' 'True' 'True' ..., 'True' 'False' 'False']\n",
      "actual_values    ['False' 'False' 'False' ..., 'False' 'False' 'False']\n",
      "\n",
      "----Linear SVC_report--------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.80      0.96      0.87      4544\n",
      "       True       0.21      0.04      0.06      1134\n",
      "\n",
      "avg / total       0.68      0.78      0.71      5678\n",
      "\n",
      "\n",
      "----Tree_report--------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.89      0.92      0.91      4544\n",
      "       True       0.63      0.54      0.58      1134\n",
      "\n",
      "avg / total       0.84      0.85      0.84      5678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(\"feature_tables/basics.csv\")\n",
    "#train(\"feature_tables/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
