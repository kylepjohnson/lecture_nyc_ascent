{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script to demo scikit for tweet popular/unpopular classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import csv\n",
    "import datetime as dt\n",
    "import os\n",
    "import platform\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def csv_to_dict_cesar(csv_filename):\n",
    "    # Let's say, We are intersted in only count features\n",
    "    count_features = ['_char_count', '_hashtag_count', '_word_count', '_url_count']\n",
    "    with open(csv_filename) as f:\n",
    "        features = [({k: int(v) for k, v in row.items() if k in count_features}, row['_popular'])\n",
    "                    for row in csv.DictReader(f, skipinitialspace=True)]\n",
    "        X = [f[0] for f in features]\n",
    "        Y = [f[1] for f in features]\n",
    "    return (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def csv_to_dict(csv_filename):\n",
    "    \"\"\"Open feature table with csv library.\n",
    "    \n",
    "    Task: Run with '_rt_count'. See the good results!\n",
    "    \"\"\"\n",
    "    non_numeric_features = ['', '_text', '_urls', '_mentions', '_hashtags', \n",
    "                            '_tweet_datetime', '_popular', '_rt_count']\n",
    "    with open(csv_filename, 'rU') as f:\n",
    "        rows = csv.DictReader(f, skipinitialspace=True, delimiter='|')\n",
    "        labels = [row['_popular'] for row in rows]\n",
    "\n",
    "    features = []\n",
    "    with open(csv_filename, 'rU') as f:\n",
    "        rows = csv.DictReader(f, skipinitialspace=True, delimiter='|')\n",
    "        for row in rows:\n",
    "            #print(row)\n",
    "            row_dict = {}\n",
    "            for k, v in row.items():\n",
    "                if k not in non_numeric_features:\n",
    "                    try:\n",
    "                        row_dict[k] = int(v)\n",
    "                    # these tries catch a few junk entries\n",
    "                    except TypeError:\n",
    "                        row_dict[k] = 0\n",
    "                    except ValueError:\n",
    "                        row_dict[k] = 0\n",
    "\n",
    "            #row_dict = {k: int(v) for k, v in row.items() if k not in non_numeric_features}\n",
    "            features.append(row_dict)                \n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def csv_to_df(csv_file):\n",
    "    \"\"\"Open csv with Pandas DataFrame, then convert to dict \n",
    "    and return.\n",
    "    \n",
    "    TODO: Fix this.\n",
    "    \"\"\"\n",
    "    \n",
    "    dataframe = pandas.read_csv(csv_file, \n",
    "                                encoding='utf-8', \n",
    "                                engine='python', \n",
    "                                sep='|',\n",
    "                                delimiter='|',\n",
    "                                index_col=0)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(csv_filename):\n",
    "    \n",
    "    print('Loading CSV into dict ...')\n",
    "    t0 = dt.datetime.utcnow()\n",
    "    data, target = csv_to_dict(csv_filename)\n",
    "    print('... finished in {} secs.'.format(dt.datetime.utcnow() - t0))\n",
    "    print()\n",
    "    \n",
    "    print('Loading dict into vectorizer')\n",
    "    t0 = dt.datetime.utcnow()\n",
    "    vec = DictVectorizer()\n",
    "    X = vec.fit_transform(data).toarray()  # change to numpy array\n",
    "    Y = np.array(target)  # change to numpy array\n",
    "    print('... finished in {} secs.'.format(dt.datetime.utcnow() - t0))\n",
    "    print()\n",
    "\n",
    "    \n",
    "    '''\n",
    "    -In case we need to know the features\n",
    "    '''\n",
    "    feature_names = vec.get_feature_names()\n",
    "\n",
    "    '''\n",
    "    -Dividing the data into train and test\n",
    "    -random_state is pseudo-random number generator state used for\n",
    "     random sampling\n",
    "    '''\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=0)\n",
    "    \n",
    "    # write models dir if not present\n",
    "    models_dir = 'models'\n",
    "    if not os.path.isdir(models_dir):\n",
    "        os.mkdir(models_dir)\n",
    "\n",
    "    '''\n",
    "    -PREPOCESSING \n",
    "    -Here, scaled data has zero mean and unit varience\n",
    "    -We save the scaler to later use with testing/prediction data\n",
    "    '''\n",
    "    print('Scaling data ...')\n",
    "    t0 = dt.datetime.utcnow()\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    joblib.dump(scaler, 'models/scaler.pickle')\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    print('... finished in {} secs.'.format(dt.datetime.utcnow() - t0))\n",
    "    print()\n",
    "    \n",
    "\n",
    "    '''\n",
    "    -This is where we define the models\n",
    "    -Here, I use SVM and Decision tree with pre-defined parameters\n",
    "    -We can learn these parameters given our data\n",
    "    '''\n",
    "    print('Defining and fitting models ...')\n",
    "    t0 = dt.datetime.utcnow()   \n",
    "    clf0 = svm.LinearSVC(C=100.)\n",
    "    clf1 = tree.DecisionTreeClassifier()\n",
    "\n",
    "    clf0.fit(X_train_scaled, Y_train)\n",
    "    clf1.fit(X_train_scaled, Y_train)\n",
    "\n",
    "    joblib.dump(clf0, 'models/svc.pickle')\n",
    "    joblib.dump(clf1, 'models/tree.pickle')\n",
    "\n",
    "    print('... finished in {} secs.'.format(dt.datetime.utcnow() - t0))\n",
    "    print()\n",
    "    \n",
    "\n",
    "    Y_prediction_svc = clf0.predict(X_test_scaled)\n",
    "    print('svc_predictions ', Y_prediction_svc)\n",
    "    Y_prediction_tree = clf1.predict(X_test_scaled)\n",
    "    print('tree_predictions ', Y_prediction_tree)\n",
    "    expected = Y_test\n",
    "    print('actual_values   ', expected)\n",
    "    print()\n",
    "\n",
    "    \n",
    "    '''\n",
    "    Classifiation metrics\n",
    "    (Case 1): SVMs\n",
    "    '''\n",
    "    print()\n",
    "    print('----Linear SVC_report--------------------------')\n",
    "    print(classification_report(expected, Y_prediction_svc))\n",
    "\n",
    "    '''\n",
    "    Classification metrics\n",
    "    (case 2): Decision tree\n",
    "    '''\n",
    "    print()\n",
    "    print('----Tree_report--------------------------------')\n",
    "    print(classification_report(expected, Y_prediction_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CSV into dict ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-17d6fc2cca29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"feature_tables/all.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-abb3c9dc02e8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(csv_filename)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loading CSV into dict ...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutcnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv_to_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'... finished in {} secs.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutcnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-8ccc891ac752>\u001b[0m in \u001b[0;36mcsv_to_dict\u001b[0;34m(csv_filename)\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnon_numeric_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                         \u001b[0mrow_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m                     \u001b[0;31m# these tries catch a few junk entries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(\"feature_tables/all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
