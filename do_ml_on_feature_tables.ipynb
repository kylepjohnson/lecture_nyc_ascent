{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script to demo scikit for tweet popular/unpopular classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import csv\n",
    "import datetime as dt\n",
    "import os\n",
    "import platform\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas\n",
    "from sklearn import clone\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def csv_to_dict_cesar(csv_filename):\n",
    "    # Let's say, We are intersted in only count features\n",
    "    count_features = ['_char_count', '_hashtag_count', '_word_count', '_url_count']\n",
    "    with open(csv_filename) as f:\n",
    "        features = [({k: int(v) for k, v in row.items() if k in count_features}, row['_popular'])\n",
    "                    for row in csv.DictReader(f, skipinitialspace=True)]\n",
    "        X = [f[0] for f in features]\n",
    "        Y = [f[1] for f in features]\n",
    "    return (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def csv_to_dict(csv_filename):\n",
    "    \"\"\"Open feature table with csv library.\n",
    "    \n",
    "    Task: Run with '_rt_count'. See the good results!\n",
    "    \"\"\"\n",
    "    non_numeric_features = ['', '_text', '_urls', '_mentions', '_hashtags', \n",
    "                            '_tweet_datetime', '_popular', '_rt_count']\n",
    "    with open(csv_filename, 'rU') as f:\n",
    "        rows = csv.DictReader(f, skipinitialspace=True, delimiter='|')\n",
    "        labels = [row['_popular'] for row in rows]\n",
    "\n",
    "    features = []\n",
    "    with open(csv_filename, 'rU') as f:\n",
    "        rows = csv.DictReader(f, skipinitialspace=True, delimiter='|')\n",
    "        for row in rows:\n",
    "            #print(row)\n",
    "            row_dict = {}\n",
    "            for k, v in row.items():\n",
    "                if k not in non_numeric_features:\n",
    "                    try:\n",
    "                        row_dict[k] = int(v)\n",
    "                    # these tries catch a few junk entries\n",
    "                    except TypeError:\n",
    "                        row_dict[k] = 0\n",
    "                    except ValueError:\n",
    "                        row_dict[k] = 0\n",
    "\n",
    "            #row_dict = {k: int(v) for k, v in row.items() if k not in non_numeric_features}\n",
    "            features.append(row_dict)                \n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def csv_to_df(csv_file):\n",
    "    \"\"\"Open csv with Pandas DataFrame, then convert to dict \n",
    "    and return.\n",
    "    \n",
    "    TODO: Fix this.\n",
    "    \"\"\"\n",
    "    \n",
    "    dataframe = pandas.read_csv(csv_file, \n",
    "                                encoding='utf-8', \n",
    "                                engine='python', \n",
    "                                sep='|',\n",
    "                                delimiter='|',\n",
    "                                index_col=0)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data(csv_filename):\n",
    "    \"\"\"Open csv file and load into Scikit vectorizer.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Open .csv and load into df\n",
    "    #features = csv_to_dict_cesar(csv_filename)\n",
    "    #vec = DictVectorizer()\n",
    "    #data = features[0]  # list of dict: [{'_word_count': 5, '_hashtag_count': 0, '_char_count': 50, '_url_count': 0}\n",
    "    #target = features[1]  # list of str: ['TRUE', 'TRUE', 'FALSE', ...]\n",
    "    \n",
    "    print('Loading CSV into dict ...')\n",
    "    t0 = dt.datetime.utcnow()\n",
    "    data, target = csv_to_dict(csv_filename)\n",
    "    print('... finished in {} secs.'.format(dt.datetime.utcnow() - t0))\n",
    "    print()\n",
    "    \n",
    "    print('Loading dict into vectorizer')\n",
    "    t0 = dt.datetime.utcnow()\n",
    "    vec = DictVectorizer()\n",
    "    X = vec.fit_transform(data).toarray()  # change to numpy array\n",
    "    Y = np.array(target)  # change to numpy array\n",
    "    print('... finished in {} secs.'.format(dt.datetime.utcnow() - t0))\n",
    "    print()\n",
    "\n",
    "    \n",
    "    '''\n",
    "    -In case we need to know the features\n",
    "    '''\n",
    "    feature_names = vec.get_feature_names()\n",
    "\n",
    "    '''\n",
    "    -Dividing the data into train and test\n",
    "    -random_state is pseudo-random number generator state used for\n",
    "     random sampling\n",
    "    '''\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=0)\n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CSV into dict ...\n",
      "... finished in 0:00:00.828561 secs.\n",
      "\n",
      "Loading dict into vectorizer\n",
      "... finished in 0:00:00.272856 secs.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = load_data(\"feature_tables/basics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scale_data(X_train, X_test, Y_train, Y_test):\n",
    "    \"\"\"Take Vectors, \n",
    "    \"\"\"\n",
    "    # write models dir if not present\n",
    "    models_dir = 'models'\n",
    "    if not os.path.isdir(models_dir):\n",
    "        os.mkdir(models_dir)\n",
    "\n",
    "    '''\n",
    "    -PREPOCESSING \n",
    "    -Here, scaled data has zero mean and unit varience\n",
    "    -We save the scaler to later use with testing/prediction data\n",
    "    '''\n",
    "    print('Scaling data ...')\n",
    "    t0 = dt.datetime.utcnow()\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    joblib.dump(scaler, 'models/scaler.pickle')\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    print('... finished in {} secs.'.format(dt.datetime.utcnow() - t0))\n",
    "    print()\n",
    "\n",
    "    return X_train_scaled, X_test_scaled, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling data ...\n",
      "... finished in 0:00:00.027093 secs.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled, X_test_scaled, Y_train, Y_test = scale_data(X_train, X_test, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_tree(X_train_scaled, X_test_scaled, Y_train, Y_test):\n",
    "    \"\"\"Run decision tree with scikit.\n",
    "    \n",
    "    Experiment with: 'max_depth'\n",
    "    \"\"\"\n",
    "    '''\n",
    "    -This is where we define the models with pre-defined parameters\n",
    "    -We can learn these parameters given our data\n",
    "    '''\n",
    "    print('Defining and fitting models ...')\n",
    "    t0 = dt.datetime.utcnow()   \n",
    "    dec_tree = DecisionTreeClassifier()\n",
    "\n",
    "    dec_tree.fit(X_train_scaled, Y_train)\n",
    "\n",
    "    joblib.dump(dec_tree, 'models/tree.pickle')\n",
    "\n",
    "    print('... finished in {} secs.'.format(dt.datetime.utcnow() - t0))\n",
    "    print()\n",
    "    \n",
    "\n",
    "    Y_prediction_tree = dec_tree.predict(X_test_scaled)\n",
    "    print('tree_predictions ', Y_prediction_tree)\n",
    "\n",
    "    expected = Y_test\n",
    "    print('actual_values   ', expected)\n",
    "\n",
    "\n",
    "    print()\n",
    "    print('----Tree_report--------------------------------')\n",
    "    print(classification_report(expected, Y_prediction_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining and fitting models ...\n",
      "... finished in 0:00:00.094537 secs.\n",
      "\n",
      "tree_predictions  ['False' 'True' 'True' ..., 'True' 'False' 'False']\n",
      "actual_values    ['False' 'False' 'False' ..., 'False' 'False' 'False']\n",
      "\n",
      "----Tree_report--------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.89      0.92      0.91      4544\n",
      "       True       0.63      0.54      0.58      1134\n",
      "\n",
      "avg / total       0.84      0.85      0.84      5678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_tree(X_train_scaled, X_test_scaled, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_svc(X_train_scaled, X_test_scaled, Y_train, Y_test):\n",
    "    \"\"\"Run SVC with scikit.\"\"\"\n",
    "    # This is where we define the models with pre-defined parameters\n",
    "    # We can learn these parameters given our data\n",
    "    print('Defining and fitting models ...')\n",
    "    t0 = dt.datetime.utcnow()   \n",
    "    scv = svm.LinearSVC(C=100.)\n",
    "\n",
    "    scv.fit(X_train_scaled, Y_train)\n",
    "\n",
    "    joblib.dump(scv, 'models/svc.pickle')\n",
    "\n",
    "    print('... finished in {} secs.'.format(dt.datetime.utcnow() - t0))\n",
    "    print()\n",
    "    \n",
    "\n",
    "    Y_prediction_svc = scv.predict(X_test_scaled)\n",
    "    print('tree_predictions ', Y_prediction_svc)\n",
    "\n",
    "    expected = Y_test\n",
    "    print('actual_values   ', expected)\n",
    "\n",
    "\n",
    "    print()\n",
    "    print('----SVC_report--------------------------------')\n",
    "    print(classification_report(expected, Y_prediction_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining and fitting models ...\n",
      "... finished in 0:00:03.905614 secs.\n",
      "\n",
      "tree_predictions  ['False' 'False' 'False' ..., 'False' 'False' 'False']\n",
      "actual_values    ['False' 'False' 'False' ..., 'False' 'False' 'False']\n",
      "\n",
      "----SVC_report--------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.80      0.96      0.87      4544\n",
      "       True       0.22      0.05      0.08      1134\n",
      "\n",
      "avg / total       0.69      0.78      0.71      5678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_svc(X_train_scaled, X_test_scaled, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_random_forest(X_train_scaled, X_test_scaled, Y_train, Y_test):\n",
    "    \"\"\"Scikit random forest\n",
    "    \n",
    "    Experiment with 'n_estimators'\n",
    "    \"\"\"\n",
    "    \n",
    "    n_estimators = 30\n",
    "    \n",
    "    rf_model = RandomForestClassifier(n_estimators=n_estimators)\n",
    "\n",
    "    # Train\n",
    "    clf = clone(rf_model)\n",
    "    clf = rf_model.fit(X_train_scaled, Y_train)\n",
    "    \n",
    "    joblib.dump(clf, 'models/random_forest.pickle')\n",
    "    \n",
    "    scores = clf.score(X_train_scaled, Y_train)\n",
    "    \n",
    "    \n",
    "    \n",
    "    Y_prediction = clf.predict(X_test_scaled)\n",
    "    print('tree_predictions ', Y_prediction)\n",
    "\n",
    "    expected = Y_test\n",
    "    print('actual_values   ', expected)\n",
    "\n",
    "\n",
    "    print()\n",
    "    print('----Random forest report--------------------------------')\n",
    "    print(classification_report(expected, Y_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree_predictions  ['False' 'True' 'True' ..., 'True' 'False' 'False']\n",
      "actual_values    ['False' 'False' 'False' ..., 'False' 'False' 'False']\n",
      "\n",
      "----Random forest report--------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.89      0.92      0.91      4544\n",
      "       True       0.64      0.56      0.60      1134\n",
      "\n",
      "avg / total       0.84      0.85      0.85      5678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_random_forest(X_train_scaled, X_test_scaled, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_ada_boost(X_train_scaled, X_test_scaled, Y_train, Y_test):\n",
    "    \"\"\"Scikit random forest.\n",
    "    \n",
    "    For plotting see:\n",
    "    http://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_iris.html\n",
    "    \n",
    "    Experiment with 'n_estimators'\n",
    "    \"\"\"\n",
    "    \n",
    "    n_estimators = 30\n",
    "    ada_classifier = AdaBoostClassifier(DecisionTreeClassifier(max_depth=3),\n",
    "                                        n_estimators=n_estimators)\n",
    "\n",
    "    # Train\n",
    "    clf = clone(ada_classifier)\n",
    "    clf = ada_classifier.fit(X_train_scaled, Y_train)\n",
    "    \n",
    "    joblib.dump(clf, 'models/ada_boost.pickle')\n",
    "    \n",
    "    scores = clf.score(X_train_scaled, Y_train)\n",
    "    \n",
    "    \n",
    "    \n",
    "    Y_prediction = clf.predict(X_test_scaled)\n",
    "    print('tree_predictions ', Y_prediction)\n",
    "\n",
    "    expected = Y_test\n",
    "    print('actual_values   ', expected)\n",
    "\n",
    "\n",
    "    print()\n",
    "    print(classification_report(expected, Y_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree_predictions  ['True' 'False' 'False' ..., 'True' 'True' 'False']\n",
      "actual_values    ['False' 'False' 'False' ..., 'False' 'False' 'False']\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.89      0.80      0.84      4544\n",
      "       True       0.43      0.63      0.51      1134\n",
      "\n",
      "avg / total       0.80      0.76      0.78      5678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_ada_boost(X_train_scaled, X_test_scaled, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
