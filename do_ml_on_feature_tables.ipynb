{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script to demo scikit for tweet popular/unpopular classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import csv\n",
    "import datetime as dt\n",
    "import os\n",
    "import platform\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def csv_to_dict_cesar(csv_filename):\n",
    "    # Let's say, We are intersted in only count features\n",
    "    count_features = ['_char_count', '_hashtag_count', '_word_count', '_url_count']\n",
    "    with open(csv_filename) as f:\n",
    "        features = [({k: int(v) for k, v in row.items() if k in count_features}, row['_popular'])\n",
    "                    for row in csv.DictReader(f, skipinitialspace=True)]\n",
    "        X = [f[0] for f in features]\n",
    "        Y = [f[1] for f in features]\n",
    "    return (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def csv_to_df(csv_file):\n",
    "    \"\"\"Open csv with Pandas DataFrame, then convert to dict \n",
    "    and return.\n",
    "    \"\"\"\n",
    "    \n",
    "    dataframe = pandas.read_csv(csv_file, \n",
    "                                encoding='utf-8', \n",
    "                                engine='python', \n",
    "                                sep='|',\n",
    "                                delimiter='|',\n",
    "                                index_col=0)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(csv_filename):\n",
    "    \n",
    "    # Open .csv and load into df\n",
    "    #features = csv_to_dict_cesar(csv_filename)\n",
    "    #vec = DictVectorizer()\n",
    "    #data = features[0]  # list of dict: [{'_word_count': 5, '_hashtag_count': 0, '_char_count': 50, '_url_count': 0}\n",
    "    #target = features[1]  # list of str: ['TRUE', 'TRUE', 'FALSE', ...]\n",
    "    \n",
    "    print('Loading CSV into DataFrame ...')\n",
    "    t0 = dt.datetime.utcnow()\n",
    "    df_features = csv_to_df(csv_filename)\n",
    "    print('... finished in {} secs.'.format(dt.datetime.utcnow() - t0))\n",
    "    print()\n",
    "    \n",
    "    # Convert df to list of dict\n",
    "    # http://stackoverflow.com/a/29815523\n",
    "    print('Loading DataFrame into vectorizer')\n",
    "    t0 = dt.datetime.utcnow()\n",
    "    print('DataFrame rows before:', len(df_features.index))\n",
    "    target_1 = df_features['_popular'].tolist()  # list of str: ['TRUE', 'TRUE', 'FALSE', ...]\n",
    "    #data_pivoted = df_features.T.to_dict().values()  # list of dict: [{u'_char_count': 140.0, u'_popular': u'True', ...}, ...]\n",
    "    print('Boolean features before pivot:', len(target_1))\n",
    "    \n",
    "    # pivot table, which (for some reason) reduces rows to 18287\n",
    "    data_pivoted = df_features.T.to_dict()\n",
    "    data_unpivoted = df_features.T.to_dict()\n",
    "    print('data_pivoted:', len(data_pivoted))\n",
    "    print('data_unpivoted:', len(data_unpivoted))\n",
    "    \n",
    "    \n",
    "    vec = DictVectorizer()\n",
    "    X = vec.fit_transform(data_pivoted).toarray()  # change to numpy array\n",
    "    Y = np.array(target)  # change to numpy array\n",
    "    print('... finished in {} secs.'.format(dt.datetime.utcnow() - t0))\n",
    "    print()\n",
    "\n",
    "    \n",
    "    '''\n",
    "    -In case we need to know the features\n",
    "    '''\n",
    "    feature_names = vec.get_feature_names()\n",
    "\n",
    "    '''\n",
    "    -Dividing the data into train and test\n",
    "    -random_state is pseudo-random number generator state used for\n",
    "     random sampling\n",
    "    '''\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=0)\n",
    "    \n",
    "    # write models dir if not present\n",
    "    models_dir = 'models'\n",
    "    if not os.path.isdir(models_dir):\n",
    "        os.mkdir(models_dir)\n",
    "\n",
    "    '''\n",
    "    -PREPOCESSING \n",
    "    -Here, scaled data has zero mean and unit varience\n",
    "    -We save the scaler to later use with testing/prediction data\n",
    "    '''\n",
    "    print('Scaling data ...')\n",
    "    t0 = dt.datetime.utcnow()\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    joblib.dump(scaler, 'models/scaler.pickle')\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    print('... finished in {} secs.'.format(dt.datetime.utcnow() - t0))\n",
    "    print()\n",
    "    \n",
    "\n",
    "    '''\n",
    "    -This is where we define the models\n",
    "    -Here, I use SVM and Decision tree with pre-defined parameters\n",
    "    -We can learn these parameters given our data\n",
    "    '''\n",
    "    print('Defining and fitting models ...')\n",
    "    t0 = dt.datetime.utcnow()   \n",
    "    clf0 = svm.LinearSVC(C=100.)\n",
    "    clf1 = tree.DecisionTreeClassifier()\n",
    "\n",
    "    clf0.fit(X_train_scaled, Y_train)\n",
    "    clf1.fit(X_train_scaled, Y_train)\n",
    "\n",
    "    joblib.dump(clf0, 'models/svc.pickle')\n",
    "    joblib.dump(clf1, 'models/tree.pickle')\n",
    "\n",
    "    print('... finished in {} secs.'.format(dt.datetime.utcnow() - t0))\n",
    "    print()\n",
    "    \n",
    "\n",
    "    Y_prediction_svc = clf0.predict(X_test_scaled)\n",
    "    print('svc_predictions ', Y_prediction_svc)\n",
    "    Y_prediction_tree = clf1.predict(X_test_scaled)\n",
    "    print('tree_predictions ', Y_prediction_tree)\n",
    "    expected = Y_test\n",
    "    print('actual_values   ', expected)\n",
    "\n",
    "    '''\n",
    "    Classifiation metrics\n",
    "    (Case 1): SVMs\n",
    "    '''\n",
    "    print()\n",
    "    print('----Linear SVC_report--------------------------')\n",
    "    print(classification_report(expected, Y_prediction_svc))\n",
    "\n",
    "    '''\n",
    "    Classification metrics\n",
    "    (case 2): Decision tree\n",
    "    '''\n",
    "    print()\n",
    "    print('----Tree_report--------------------------------')\n",
    "    print(classification_report(expected, Y_prediction_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CSV into DataFrame ...\n",
      "... finished in 0:00:00.648989 secs.\n",
      "\n",
      "Loading DataFrame into vectorizer\n",
      "DataFrame rows before: 22709\n",
      "Boolean features before pivot: 22709\n",
      "data_pivoted: 18287\n",
      "data_unpivoted: 18287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kyle/tensorflow/tensorflow/examples/udacity/venv27/lib/python2.7/site-packages/pandas/core/frame.py:835: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  \"columns will be omitted.\", UserWarning)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-121a0e9e86ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"feature_tables/basics.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#train(\"feature_tables/test.csv\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-65d44de1fc88>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(csv_filename)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDictVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_pivoted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# change to numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# change to numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'... finished in {} secs.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutcnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kyle/tensorflow/tensorflow/examples/udacity/venv27/lib/python2.7/site-packages/sklearn/feature_extraction/dict_vectorizer.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mFeature\u001b[0m \u001b[0mvectors\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0malways\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \"\"\"\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kyle/tensorflow/tensorflow/examples/udacity/venv27/lib/python2.7/site-packages/sklearn/feature_extraction/dict_vectorizer.pyc\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, X, fitting)\u001b[0m\n\u001b[1;32m    172\u001b[0m                         \u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                         \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m                         \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mindptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number"
     ]
    }
   ],
   "source": [
    "train(\"feature_tables/basics.csv\")\n",
    "#train(\"feature_tables/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
