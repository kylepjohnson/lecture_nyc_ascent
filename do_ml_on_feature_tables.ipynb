{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script to demo scikit for tweet popular/unpopular classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import csv\n",
    "import datetime as dt\n",
    "import os\n",
    "import platform\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def csv_to_dict_cesar(csv_filename):\n",
    "    # Let's say, We are intersted in only count features\n",
    "    count_features = ['_char_count', '_hashtag_count', '_word_count', '_url_count']\n",
    "    with open(csv_filename) as f:\n",
    "        features = [({k: int(v) for k, v in row.items() if k in count_features}, row['_popular'])\n",
    "                    for row in csv.DictReader(f, skipinitialspace=True)]\n",
    "        X = [f[0] for f in features]\n",
    "        Y = [f[1] for f in features]\n",
    "    return (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def csv_to_dict_kyle(csv_filename):\n",
    "    # Let's say, We are intersted in only count features\n",
    "    count_features = ['_char_count', '_hashtag_count', '_word_count', '_url_count']\n",
    "    with open(csv_filename) as f:\n",
    "        for row in csv.DictReader(f, skipinitialspace=True, delimiter='|'):\n",
    "            if row:\n",
    "                print(row)['_word_count']\n",
    "            #input()\n",
    "        '''\n",
    "        features = [({k: int(v) for k, v in row.items() if k in count_features}, row['_popular'])\n",
    "                    for row in csv.DictReader(f, skipinitialspace=True)]\n",
    "        X = [f[0] for f in features]\n",
    "        Y = [f[1] for f in features]\n",
    "        '''\n",
    "    return (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'': '0', '_urls': '[https://t.co/dnF3Wqdt1C]', '_char_count': '50', '_hashtags': '[]', '_mentions': '[@CringeLMAO]', '_rt_count': '2084', '_hashtag_count': '0', '_tweet_datetime': 'Mon Feb 15 20:44:33 +0000 2016', '_word_count': '5', '_text': '@CringeLMAO: Easy there m8 https://t.co/dnF3Wqdt1C', '_url_count': '1', '_popular': 'True', '_mentions_count': '1'}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object has no attribute '__getitem__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-cf40cdcb6776>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv_to_dict_kyle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'feature_tables/basics.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-1a5e5c39c4d4>\u001b[0m in \u001b[0;36mcsv_to_dict_kyle\u001b[0;34m(csv_filename)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipinitialspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'|'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                 \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_word_count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0;31m#input()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         '''\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object has no attribute '__getitem__'"
     ]
    }
   ],
   "source": [
    "x, y = csv_to_dict_kyle('feature_tables/basics.csv')\n",
    "print(x[:2])\n",
    "print(y[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def csv_to_df(csv_file):\n",
    "    \"\"\"Open csv with Pandas DataFrame, then convert to dict \n",
    "    and return.\n",
    "    \"\"\"\n",
    "    \n",
    "    dataframe = pandas.read_csv(csv_file, \n",
    "                                encoding='utf-8', \n",
    "                                engine='python', \n",
    "                                sep='|',\n",
    "                                delimiter='|',\n",
    "                                index_col=0)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(csv_filename):\n",
    "    \n",
    "    # Open .csv and load into df\n",
    "    #features = csv_to_dict_cesar(csv_filename)\n",
    "    #vec = DictVectorizer()\n",
    "    #data = features[0]  # list of dict: [{'_word_count': 5, '_hashtag_count': 0, '_char_count': 50, '_url_count': 0}\n",
    "    #target = features[1]  # list of str: ['TRUE', 'TRUE', 'FALSE', ...]\n",
    "    \n",
    "    print('Loading CSV into DataFrame ...')\n",
    "    t0 = dt.datetime.utcnow()\n",
    "    df_features = csv_to_df(csv_filename)\n",
    "    print('... finished in {} secs.'.format(dt.datetime.utcnow() - t0))\n",
    "    print()\n",
    "    \n",
    "    # Convert df to list of dict\n",
    "    # http://stackoverflow.com/a/29815523\n",
    "    print('Loading DataFrame into vectorizer')\n",
    "    t0 = dt.datetime.utcnow()\n",
    "    target = df_features['_popular'].tolist()  # list of str: ['TRUE', 'TRUE', 'FALSE', ...]\n",
    "    data = df_features.T.to_dict().values()  # list of dict: [{u'_char_count': 140.0, u'_popular': u'True', ...}, ...]\n",
    "    \n",
    "    vec = DictVectorizer()\n",
    "    X = vec.fit_transform(data).toarray()  # change to numpy array\n",
    "    Y = np.array(target)  # change to numpy array\n",
    "    print('... finished in {} secs.'.format(dt.datetime.utcnow() - t0))\n",
    "    print()\n",
    "\n",
    "    \n",
    "    '''\n",
    "    -In case we need to know the features\n",
    "    '''\n",
    "    feature_names = vec.get_feature_names()\n",
    "\n",
    "    '''\n",
    "    -Dividing the data into train and test\n",
    "    -random_state is pseudo-random number generator state used for\n",
    "     random sampling\n",
    "    '''\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=0)\n",
    "    \n",
    "    # write models dir if not present\n",
    "    models_dir = 'models'\n",
    "    if not os.path.isdir(models_dir):\n",
    "        os.mkdir(models_dir)\n",
    "\n",
    "    '''\n",
    "    -PREPOCESSING \n",
    "    -Here, scaled data has zero mean and unit varience\n",
    "    -We save the scaler to later use with testing/prediction data\n",
    "    '''\n",
    "    print('Scaling data ...')\n",
    "    t0 = dt.datetime.utcnow()\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    joblib.dump(scaler, 'models/scaler.pickle')\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    print('... finished in {} secs.'.format(dt.datetime.utcnow() - t0))\n",
    "    print()\n",
    "    \n",
    "\n",
    "    '''\n",
    "    -This is where we define the models\n",
    "    -Here, I use SVM and Decision tree with pre-defined parameters\n",
    "    -We can learn these parameters given our data\n",
    "    '''\n",
    "    print('Defining and fitting models ...')\n",
    "    t0 = dt.datetime.utcnow()   \n",
    "    clf0 = svm.LinearSVC(C=100.)\n",
    "    clf1 = tree.DecisionTreeClassifier()\n",
    "\n",
    "    clf0.fit(X_train_scaled, Y_train)\n",
    "    clf1.fit(X_train_scaled, Y_train)\n",
    "\n",
    "    joblib.dump(clf0, 'models/svc.pickle')\n",
    "    joblib.dump(clf1, 'models/tree.pickle')\n",
    "\n",
    "    print('... finished in {} secs.'.format(dt.datetime.utcnow() - t0))\n",
    "    print()\n",
    "    \n",
    "\n",
    "    Y_prediction_svc = clf0.predict(X_test_scaled)\n",
    "    print('svc_predictions ', Y_prediction_svc)\n",
    "    Y_prediction_tree = clf1.predict(X_test_scaled)\n",
    "    print('tree_predictions ', Y_prediction_tree)\n",
    "    expected = Y_test\n",
    "    print('actual_values   ', expected)\n",
    "\n",
    "    '''\n",
    "    Classifiation metrics\n",
    "    (Case 1): SVMs\n",
    "    '''\n",
    "    print()\n",
    "    print('----Linear SVC_report--------------------------')\n",
    "    print(classification_report(expected, Y_prediction_svc))\n",
    "\n",
    "    '''\n",
    "    Classification metrics\n",
    "    (case 2): Decision tree\n",
    "    '''\n",
    "    print()\n",
    "    print('----Tree_report--------------------------------')\n",
    "    print(classification_report(expected, Y_prediction_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CSV into DataFrame ...\n",
      "... finished in 0:00:00.727908 secs.\n",
      "\n",
      "Loading DataFrame into vectorizer\n",
      "... finished in 0:00:01.789865 secs.\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found arrays with inconsistent numbers of samples: [18287 22709]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-121a0e9e86ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"feature_tables/basics.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#train(\"feature_tables/test.csv\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-933826b5c10c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(csv_filename)\u001b[0m\n\u001b[1;32m     37\u001b[0m      \u001b[0mrandom\u001b[0m \u001b[0msampling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     '''\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# write models dir if not present\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kyle/tensorflow/tensorflow/examples/udacity/venv27/lib/python2.7/site-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   1904\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtrain_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1905\u001b[0m         \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1906\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1907\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstratify\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1908\u001b[0m         cv = StratifiedShuffleSplit(stratify, test_size=test_size,\n",
      "\u001b[0;32m/Users/kyle/tensorflow/tensorflow/examples/udacity/venv27/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kyle/tensorflow/tensorflow/examples/udacity/venv27/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         raise ValueError(\"Found arrays with inconsistent numbers of samples: \"\n\u001b[0;32m--> 176\u001b[0;31m                          \"%s\" % str(uniques))\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found arrays with inconsistent numbers of samples: [18287 22709]"
     ]
    }
   ],
   "source": [
    "train(\"feature_tables/basics.csv\")\n",
    "#train(\"feature_tables/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
